# Version Control Process

## Initial Setup
- **Forking the Repository**: A fork of the existing repository was created on GitHub to start independent development work.

## Feature Development: Adding Delivery Date
- **Issue Creation**: Opened a new issue in the GitHub repository, describing the need to add a 'Delivery Date' field to the Microsoft Azure SQL Server database.
- **Branch Creation**: Created a feature branch named `feature/add-delivery-date` from the main branch to work on this specific feature.
- **Code Modification**:
  - Edited `app.py` to implement the functionality of adding a 'Delivery Date' field to the database.
  - Updated `orders.html` to display the new 'Delivery Date' field.
- **Pushing Changes**:
  - Committed the changes and used `git push` to upload the updates to the `feature/add-delivery-date` branch on GitHub.
- **Pull Request for Peer Review**:
  - Created a pull request to merge changes from `feature/add-delivery-date` into the `main` branch.
  - The pull request was titled appropriately and included a detailed description for peer review.

## Feature Integration
- **Merging the Feature**:
  - After review and approval, the pull request was merged, and the `main` branch was updated with the new 'Delivery Date' feature.

## Reverting the Feature
- **Decision to Revert**:
  - Later, it was decided that the 'Delivery Date' feature was unnecessary.
- **Creating a Revert Branch**: 
  - Created a new branch named `revert/delivery-date-feature` for handling the revert process.
- **Reverting Changes**:
  - Performed a `git revert` to the commit prior to the merge of the 'Delivery Date' feature.
  - Ensured that the revert commit message clearly explained the reason for the revert.
- **Finalizing Revert**:
  - Pushed the revert commit to the `revert/delivery-date-feature` branch.
  - Opened a new pull request to merge the revert changes into the `main` branch.
- **Completing the Revert Merge**:
  - After review, the pull request was merged, effectively reverting the `main` branch to its state before the 'Delivery Date' feature was added.

### Notes:
- **Commit Messages**: Ensured that all commit messages were clear and descriptive of the changes made and the purpose of each commit.
- **Documentation and Comments**: Updated relevant documentation and code comments to reflect changes during each step of the process.
- **Testing**: Before each push and pull request, local testing was performed to ensure functionality and to prevent integration issues.

# Containerization Process

### Objective
- Describe the purpose of containerizing the application. Mention the benefits such as consistency across environments, ease of deployment, etc.

### Creating Dockerfile

- **Base Image**: Explain why you chose the specific base image (e.g., `python:3.8-slim`).
- **Setting Up the Working Directory**: Document the command to set up the working directory in the Docker container (e.g., `WORKDIR /app`).
- **Copying Application Files**: Include the command for copying application files into the container (e.g., `COPY . /app`).
- **Installing Dependencies**: Detail the steps for installing system dependencies and any specific libraries.
- **Python Dependencies**: Mention how `requirements.txt` is used to install Python packages.
- **Exposing Ports**: Document the ports that are exposed for the application.
- **Startup Command**: Include the command that runs the application within the container.

## Docker Commands

### Building Image
- **Command**: `docker build -t <image-name> .`
- **Explanation**: Describes how to build the Docker image from the Dockerfile.

### Running Containers
- **Command**: `docker run -d -p <host-port>:<container-port> <image-name>`
- **Explanation**: Details on how to run the container, mapping container ports to host ports.

### Tagging for Docker Hub
- **Command**: `docker tag <local-image-name> <docker-hub-username>/<image-name>:<tag>`
- **Explanation**: Describes how to tag a local image for pushing to Docker Hub.

### Pushing to Docker Hub
- **Command**: `docker push <docker-hub-username>/<image-name>:<tag>`
- **Explanation**: Details on how to push the tagged image to Docker Hub.

## Image Information

- **Image Name and Tags**: Document the Docker image name and tags used.
- **Usage Instructions**: Provide any specific instructions or prerequisites needed to use the Docker image.

## Cleanup

### Remove Containers

#### Listing Containers
- **Command**: `docker ps -a`
- **Explanation**: Lists all containers, including the stopped ones.

#### Removing Containers
- **Command**: `docker rm <container-id>`
- **Explanation**: Removes specified containers. Useful for cleaning up resources.

### Remove Images

#### Listing Images
- **Command**: `docker images -a`
- **Explanation**: Shows all Docker images on the host.

#### Removing Images
- **Command**: `docker rmi <image-id>`
- **Explanation**: Removes specified Docker images. Helps in reclaiming disk space.

## Note
- Ensure accuracy and clarity in documentation for effective knowledge sharing.
- Regularly update the documentation to reflect changes in the containerization process or Docker commands used.
- The cleanup process is important to prevent resource hogging and to maintain a lean development environment.

# Terraform Azure Network Infrastructure Setup

## Overview

This guide provides a step-by-step process to set up the Azure Kubernetes Service (AKS) infrastructure using Terraform. Terraform lets us define our infrastructure as code, making it easier to manage and update. This approach brings flexibility, customization, and a well-organized structure to our network setup.

## Setting Up Variables

### `variables.tf`

The `variables.tf` file in the networking module defines several variables. These variables make our configuration flexible, customizable, and well-organized.

- **Resource Group Name**: Identifies the Azure Resource Group for networking resources. It's set to `myResourceGroup` by default but can be changed as needed.
- **Location**: Specifies the Azure region for deploying resources. Default is set to `East US`.
- **Virtual Network Address Space**: Defines the address range for the Virtual Network, with a default set to `10.0.0.0/16`.

## Defining Networking Resources

### `main.tf`

The `main.tf` file in the networking module includes definitions for critical networking resources:

- **Azure Resource Group (`azurerm_resource_group`)**: Organizes all networking resources under a single group, simplifying management.
- **Virtual Network (`azurerm_virtual_network`)**: Sets up an isolated network (VNet) for the AKS cluster, ensuring isolation and segmentation.
- **Subnets for Control Plane and Worker Nodes (`azurerm_subnet`)**: Allocates specific network segments within the VNet for AKS components. The control plane and worker nodes are separated for enhanced organization and security.
- **Network Security Group (`azurerm_network_security_group`)**: Implements security rules for the AKS cluster, controlling inbound and outbound traffic. This includes rules for Kubernetes API server and SSH access.

### Security Rules in NSG

- **Kubernetes API Server Rule**: Allows inbound TCP traffic on port 443 from a specific source IP.
- **SSH Rule**: Permits inbound SSH (port 22) traffic from the same specific source IP.

## Outputs Defined

### `outputs.tf`

This file specifies the outputs that provide important information after deploying the resources:

- **VNet ID (`vnet_id`)**: Outputs the ID of the Virtual Network.
- **Control Plane Subnet ID (`control_plane_subnet_id`)**: Provides the ID for the control plane subnet.
- **Worker Node Subnet ID (`worker_node_subnet_id`)**: Gives the ID for the worker node subnet.
- **Networking Resource Group Name (`networking_resource_group_name`)**: Outputs the name of the Azure Resource Group used.
- **AKS NSG ID (`aks_nsg_id`)**: Outputs the ID of the Network Security Group.

By following these steps and using the provided Terraform code, you can efficiently set up a robust and secure AKS infrastructure in Azure.

# Terraform Configuration for Azure Kubernetes Service (AKS) Cluster

## Provider Block
- **azurerm**: This provider block indicates that Azure is the cloud provider for this Terraform configuration.

## Resource: azurerm_kubernetes_cluster
- **name**: Specifies the name of the AKS cluster, which is pulled from a variable.
- **location**: Determines the location/region where the AKS cluster will be created.
- **resource_group_name**: The name of the resource group in Azure where the AKS cluster will reside.
- **dns_prefix**: Sets a DNS prefix for the AKS cluster, utilized for the Kubernetes API server FQDN (Fully Qualified Domain Name).

## Default Node Pool
This section defines the default node pool for the AKS cluster.
- **name**: A name for the node pool.
- **node_count**: The number of nodes (Virtual Machines) in the node pool.
- **vm_size**: The size of the Virtual Machines in the node pool.

## Service Principal
This part provides details about the service principal used by AKS for interacting with other Azure services.
- **client_id**: The Client ID of the service principal.
- **client_secret**: The Client Secret of the service principal.

# Outputs for Azure Kubernetes Service (AKS) Cluster Module

## Introduction
In the `outputs.tf` file of the AKS cluster module, we define important output variables. These variables will capture essential information about the provisioned AKS cluster.

## Output Variables

### `aks_cluster_name`
- **Description**: This variable holds the name of the AKS cluster that has been provisioned.
- **Value**: The actual name of the AKS cluster as it's created in Azure.
  
### `aks_cluster_id`
- **Description**: Stores the unique identifier (ID) of the provisioned AKS cluster.
- **Value**: The ID is assigned by Azure when the AKS cluster is created.

### `aks_kubeconfig`
- **Description**: Captures the Kubernetes configuration file. This file is crucial for interacting with and managing the AKS cluster using `kubectl`.
- **Value**: It's the raw configuration file needed to connect to and manage the AKS cluster.

## Summary
By defining these output variables, we can easily retrieve and use key information about our AKS cluster, such as its name, ID, and configuration details for Kubernetes management.
